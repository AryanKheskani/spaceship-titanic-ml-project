{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><b>GROUP 96: SPACESHIP TITANIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Project by: Aryan Kheskani, Aryan Rajput, Gaelle Nehme, Gonzalo Lantero, Lama Abboud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = train_data.isnull().sum() / len(train_data) * 100\n",
    "missing_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>How does applying Principal Component Analysis (PCA) to the dataset affect model performance, and what is the trade-off between the number of principal components retained and the modelâ€™s predictive accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing and basic feature engineering<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing values - Fill numerical columns with median, categorical with mode\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':  # Categorical columns\n",
    "        train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n",
    "    else:  # Numerical columns\n",
    "        train_data[col].fillna(train_data[col].median(), inplace=True)\n",
    "\n",
    "# Print dataset after missing value handling\n",
    "print(\"\\nDataset after handling missing values:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Encode categorical variables\n",
    "# encoder = LabelEncoder()\n",
    "# for col in train_data.select_dtypes(include=['object']).columns:\n",
    "#     train_data[col] = encoder.fit_transform(train_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = train_data.drop(columns=['Transported'])  # Features\n",
    "y = train_data['Transported'].astype(int)  # Target (1 = Transported, 0 = Not Transported)\n",
    "\n",
    "# Print dataset after encoding\n",
    "print(\"\\nDataset after encoding categorical variables:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train & test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features for PCA\n",
    "scaler = StandardScaler() # the scalar object is used to scale the data so that the data has mean = 0 and variance = 1\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Print shape of training and test sets\n",
    "print(\"\\nShape of training data:\", X_train.shape)\n",
    "print(\"Shape of test data:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative explained variance to determine optimal number of components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance Threshold')\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA - Explained Variance vs Number of Components\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.argmax(explained_variance_ratio >= 0.95) + 1\n",
    "print(f\"\\nOptimal number of components to retain 95% variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# Apply PCA with optimal components\n",
    "pca_optimal = PCA(n_components=n_components)\n",
    "X_train_pca_optimal = pca_optimal.fit_transform(X_train_scaled)\n",
    "X_test_pca_optimal = pca_optimal.transform(X_test_scaled)\n",
    "\n",
    "# Train a Random Forest Classifier before and after PCA\n",
    "rf_before = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_before.fit(X_train, y_train)\n",
    "\n",
    "rf_after = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_after.fit(X_train_pca_optimal, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_before = rf_before.predict(X_test)\n",
    "y_pred_after = rf_after.predict(X_test_pca_optimal)\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics = {\n",
    "    \"Accuracy\": [accuracy_score(y_test, y_pred_before), accuracy_score(y_test, y_pred_after)],\n",
    "    \"ROC AUC\": [roc_auc_score(y_test, y_pred_before), roc_auc_score(y_test, y_pred_after)],\n",
    "    \"F1 Score\": [f1_score(y_test, y_pred_before), f1_score(y_test, y_pred_after)]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Before PCA\", \"After PCA\"])\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>apply advanced feature engineering<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Apply one-hot encoding<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns:\n",
      "Index(['HomePlanet', 'CryoSleep', 'Destination', 'VIP'], dtype='object')\n",
      "\n",
      "Numerical columns:\n",
      "Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
    "print(\"\\nCategorical columns:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nNumerical columns:\")\n",
    "print(numerical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>handle missing values<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].mode()[0], inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_data[col].fillna(test_data[col].mode()[0], inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(train_data[col].median(), inplace=True)\n",
      "/var/folders/wc/9t3nbx396_l8btwwt3qwz_lw0000gn/T/ipykernel_45672/1480895698.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data[col].fillna(test_data[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values for categorical features with the mode\n",
    "for col in categorical_cols:\n",
    "    train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n",
    "    test_data[col].fillna(test_data[col].mode()[0], inplace=True)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    train_data[col].fillna(train_data[col].median(), inplace=True)\n",
    "    test_data[col].fillna(test_data[col].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after encoding categorical variables:\n",
      "    Age  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Transported  \\\n",
      "0  39.0          0.0        0.0           0.0     0.0     0.0        False   \n",
      "1  24.0        109.0        9.0          25.0   549.0    44.0         True   \n",
      "2  58.0         43.0     3576.0           0.0  6715.0    49.0        False   \n",
      "3  33.0          0.0     1283.0         371.0  3329.0   193.0        False   \n",
      "4  16.0        303.0       70.0         151.0   565.0     2.0         True   \n",
      "\n",
      "   HomePlanet_Earth  HomePlanet_Europa  HomePlanet_Mars  CryoSleep_False  \\\n",
      "0               0.0                1.0              0.0              1.0   \n",
      "1               1.0                0.0              0.0              1.0   \n",
      "2               0.0                1.0              0.0              1.0   \n",
      "3               0.0                1.0              0.0              1.0   \n",
      "4               1.0                0.0              0.0              1.0   \n",
      "\n",
      "   CryoSleep_True  Destination_55 Cancri e  Destination_PSO J318.5-22  \\\n",
      "0             0.0                      0.0                        0.0   \n",
      "1             0.0                      0.0                        0.0   \n",
      "2             0.0                      0.0                        0.0   \n",
      "3             0.0                      0.0                        0.0   \n",
      "4             0.0                      0.0                        0.0   \n",
      "\n",
      "   Destination_TRAPPIST-1e  VIP_False  VIP_True  \n",
      "0                      1.0        1.0       0.0  \n",
      "1                      1.0        1.0       0.0  \n",
      "2                      1.0        0.0       1.0  \n",
      "3                      1.0        1.0       0.0  \n",
      "4                      1.0        1.0       0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "#fit and transform the data\n",
    "encoded_train = encoder.fit_transform(train_data[categorical_cols])\n",
    "encoded_test = encoder.transform(test_data[categorical_cols])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original categorical columns and merge encoded features\n",
    "train_df = train_data.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "test_df = test_data.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "\n",
    "train_df = pd.concat([train_df, encoded_train_df], axis=1)\n",
    "test_df = pd.concat([test_df, encoded_test_df], axis=1)\n",
    "\n",
    "# Print dataset after encoding\n",
    "print(\"\\nDataset after encoding categorical variables:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Apply scaling<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after scaling:\n",
      "        Age  RoomService  FoodCourt  ShoppingMall       Spa    VRDeck  \\\n",
      "0  0.711945    -0.333105  -0.281027     -0.283579 -0.270626 -0.263003   \n",
      "1 -0.334037    -0.168073  -0.275387     -0.241771  0.217158 -0.224205   \n",
      "2  2.036857    -0.268001   1.959998     -0.283579  5.695623 -0.219796   \n",
      "3  0.293552    -0.333105   0.523010      0.336851  2.687176 -0.092818   \n",
      "4 -0.891895     0.125652  -0.237159     -0.031059  0.231374 -0.261240   \n",
      "\n",
      "   Transported  HomePlanet_Earth  HomePlanet_Europa  HomePlanet_Mars  \\\n",
      "0        False               0.0                1.0              0.0   \n",
      "1         True               1.0                0.0              0.0   \n",
      "2        False               0.0                1.0              0.0   \n",
      "3        False               0.0                1.0              0.0   \n",
      "4         True               1.0                0.0              0.0   \n",
      "\n",
      "   CryoSleep_False  CryoSleep_True  Destination_55 Cancri e  \\\n",
      "0              1.0             0.0                      0.0   \n",
      "1              1.0             0.0                      0.0   \n",
      "2              1.0             0.0                      0.0   \n",
      "3              1.0             0.0                      0.0   \n",
      "4              1.0             0.0                      0.0   \n",
      "\n",
      "   Destination_PSO J318.5-22  Destination_TRAPPIST-1e  VIP_False  VIP_True  \n",
      "0                        0.0                      1.0        1.0       0.0  \n",
      "1                        0.0                      1.0        1.0       0.0  \n",
      "2                        0.0                      1.0        0.0       1.0  \n",
      "3                        0.0                      1.0        1.0       0.0  \n",
      "4                        0.0                      1.0        1.0       0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Initialize scalers\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Apply Standardization\n",
    "X_standardized = train_df.copy()\n",
    "X_standardized[numerical_cols] = standard_scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "# Apply Normalization\n",
    "X_normalized = train_df.copy()\n",
    "X_normalized[numerical_cols] = minmax_scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "# Print dataset after scaling\n",
    "print(\"\\nDataset after scaling:\")\n",
    "print(X_standardized.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>testing on different modelling approaches<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaellenehme/Library/Python/3.11/lib/python/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance on Validation Set:\n",
      "                    Model  Validation Accuracy\n",
      "0     Logistic Regression             0.772858\n",
      "1           Random Forest             0.772858\n",
      "2  Support Vector Machine             0.774008\n",
      "3     K-Nearest Neighbors             0.773433\n",
      "4             Naive Bayes             0.733755\n",
      "5       Gradient Boosting             0.780909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#target variable = what we are trying to predict\n",
    "target = 'Transported'\n",
    "X = train_df.drop(columns=[target])\n",
    "y = train_df[target]\n",
    "\n",
    "# Split dataset into train & test sets (80/20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train & evaluate each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    results.append({\"Model\": name, \"Validation Accuracy\": accuracy})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Performance on Validation Set:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
